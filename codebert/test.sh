python why_run.py --do_test --model_type roberta --model_name_or_path /home/zxw/llm/codebert/microsoft/codebert-base --load_model_path /home/zxw/inlinegeneration/codebert/code/model/why/why_checkpoint-best-bleu/why_pytorch_model.bin --dev_filename /home/zxw/inlinegeneration/codebert/dataset/why_valid.jsonl --test_filename /home/zxw/llm/codebert/why_sample_test.jsonl --output_dir model/why --max_source_length 128 --max_target_length 32 --beam_size 5 --eval_batch_size 64  > output/test_why_4.log 2>&1
python why_run.py --do_test --model_type roberta --model_name_or_path /home/zxw/llm/codebert/microsoft/codebert-base --load_model_path /home/zxw/inlinegeneration/codebert/code/model/why/why_checkpoint-best-bleu/why_pytorch_model.bin --dev_filename /home/zxw/inlinegeneration/codebert/dataset/why_valid.jsonl --test_filename /home/zxw/llm/codebert/why_sample_test.jsonl --output_dir model/why --max_source_length 128 --max_target_length 32 --beam_size 5 --eval_batch_size 64  > output/test_why_3.log 2>&1
python why_run.py --do_test --model_type roberta --model_name_or_path /home/zxw/llm/codebert/microsoft/codebert-base --load_model_path /home/zxw/inlinegeneration/codebert/code/model/why/why_checkpoint-best-bleu/why_pytorch_model.bin --dev_filename /home/zxw/inlinegeneration/codebert/dataset/why_valid.jsonl --test_filename /home/zxw/llm/codebert/why_sample_test.jsonl --output_dir model/why --max_source_length 128 --max_target_length 32 --beam_size 5 --eval_batch_size 64  > output/test_why_2.log 2>&1
python why_run.py --do_test --model_type roberta --model_name_or_path /home/zxw/llm/codebert/microsoft/codebert-base --load_model_path /home/zxw/inlinegeneration/codebert/code/model/why/why_checkpoint-best-bleu/why_pytorch_model.bin --dev_filename /home/zxw/inlinegeneration/codebert/dataset/why_valid.jsonl --test_filename /home/zxw/llm/codebert/why_sample_test.jsonl --output_dir model/why --max_source_length 128 --max_target_length 32 --beam_size 5 --eval_batch_size 64  > output/test_why_1.log 2>&1



python what_run_try.py --do_test --model_type roberta --model_name_or_path /home/zxw/llm/codebert/microsoft/codebert-base --load_model_path /home/zxw/inlinegeneration/codebert/code/model/what_with_duan_try/what_checkpoint-best-bleu/what_pytorch_model.bin --dev_filename /home/zxw/inlinegeneration/codebert/dataset/what_valid.jsonl --test_filename /home/zxw/llm/codebert/what_sample_test.jsonl --output_dir model/what --max_source_length 128 --max_target_length 32 --beam_size 5 --eval_batch_size 64  > output/test_what_4.log 2>&1
python what_run_try.py --do_test --model_type roberta --model_name_or_path /home/zxw/llm/codebert/microsoft/codebert-base --load_model_path /home/zxw/inlinegeneration/codebert/code/model/what_with_duan_try/what_checkpoint-best-bleu/what_pytorch_model.bin --dev_filename /home/zxw/inlinegeneration/codebert/dataset/what_valid.jsonl --test_filename /home/zxw/llm/codebert/what_sample_test.jsonl --output_dir model/what --max_source_length 128 --max_target_length 32 --beam_size 5 --eval_batch_size 64  > output/test_what_3.log 2>&1
python what_run_try.py --do_test --model_type roberta --model_name_or_path /home/zxw/llm/codebert/microsoft/codebert-base --load_model_path /home/zxw/inlinegeneration/codebert/code/model/what_with_duan_try/what_checkpoint-best-bleu/what_pytorch_model.bin --dev_filename /home/zxw/inlinegeneration/codebert/dataset/what_valid.jsonl --test_filename /home/zxw/llm/codebert/what_sample_test.jsonl --output_dir model/what --max_source_length 128 --max_target_length 32 --beam_size 5 --eval_batch_size 64  > output/test_what_2.log 2>&1
python what_run_try.py --do_test --model_type roberta --model_name_or_path /home/zxw/llm/codebert/microsoft/codebert-base --load_model_path /home/zxw/inlinegeneration/codebert/code/model/what_with_duan_try/what_checkpoint-best-bleu/what_pytorch_model.bin --dev_filename /home/zxw/inlinegeneration/codebert/dataset/what_valid.jsonl --test_filename /home/zxw/llm/codebert/what_sample_test.jsonl --output_dir model/what --max_source_length 128 --max_target_length 32 --beam_size 5 --eval_batch_size 64  > output/test_what_1.log 2>&1




python how_run.py --do_test --model_type roberta --model_name_or_path /home/zxw/llm/codebert/microsoft/codebert-base --load_model_path /home/zxw/inlinegeneration/codebert/code/model/how/how_checkpoint-best-bleu/how_pytorch_model.bin --dev_filename /home/zxw/inlinegeneration/codebert/dataset/how_valid.jsonl --test_filename /home/zxw/llm/codebert/how_sample_test.jsonl --output_dir model/how --max_source_length 128 --max_target_length 32 --beam_size 5 --eval_batch_size 64  > output/test_how_4.log 2>&1
python how_run.py --do_test --model_type roberta --model_name_or_path /home/zxw/llm/codebert/microsoft/codebert-base --load_model_path /home/zxw/inlinegeneration/codebert/code/model/how/how_checkpoint-best-bleu/how_pytorch_model.bin --dev_filename /home/zxw/inlinegeneration/codebert/dataset/how_valid.jsonl --test_filename /home/zxw/llm/codebert/how_sample_test.jsonl --output_dir model/how --max_source_length 128 --max_target_length 32 --beam_size 5 --eval_batch_size 64  > output/test_how_3.log 2>&1
python how_run.py --do_test --model_type roberta --model_name_or_path /home/zxw/llm/codebert/microsoft/codebert-base --load_model_path /home/zxw/inlinegeneration/codebert/code/model/how/how_checkpoint-best-bleu/how_pytorch_model.bin --dev_filename /home/zxw/inlinegeneration/codebert/dataset/how_valid.jsonl --test_filename /home/zxw/llm/codebert/how_sample_test.jsonl --output_dir model/how --max_source_length 128 --max_target_length 32 --beam_size 5 --eval_batch_size 64  > output/test_how_2.log 2>&1
python how_run.py --do_test --model_type roberta --model_name_or_path /home/zxw/llm/codebert/microsoft/codebert-base --load_model_path /home/zxw/inlinegeneration/codebert/code/model/how/how_checkpoint-best-bleu/how_pytorch_model.bin --dev_filename /home/zxw/inlinegeneration/codebert/dataset/how_valid.jsonl --test_filename /home/zxw/llm/codebert/how_sample_test.jsonl --output_dir model/how --max_source_length 128 --max_target_length 32 --beam_size 5 --eval_batch_size 64  > output/test_how_1.log 2>&1

